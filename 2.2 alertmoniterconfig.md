Here is a clean and proper **Alertmanager configuration file (alertmanager.yml)** used in Kubernetes or standalone setups.
Iâ€™ll provide:

âœ” Simple working config
âœ” Explained version
âœ” Kubernetes Secret example

---

# âœ… **Basic alertmanager.yml**

```yaml
global:
  resolve_timeout: 5m

route:
  receiver: "default-receiver"
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 1h

receivers:
  - name: "default-receiver"
    email_configs:
      - to: "alerts@example.com"
        from: "alertmanager@example.com"
        smarthost: "smtp.example.com:587"
        auth_username: "alertmanager@example.com"
        auth_password: "password123"

inhibit_rules:
  - source_match:
      severity: "critical"
    target_match:
      severity: "warning"
    equal: ["alertname", "instance"]
```

---

# ğŸ§¾ **Explanation (Very Simple)**

### **global**

* `resolve_timeout`: After alert resolves, how long Alertmanager waits before sending "resolved".

### **route**

Controls **how alerts flow**:

* `receiver`: default receiver
* `group_wait`: wait before sending first alert
* `group_interval`: delay between grouped alerts
* `repeat_interval`: resend if still firing

### **receivers**

Where alerts are delivered:

* `email_configs`
* Could also be **Slack**, **PagerDuty**, **Webhook**, **Opsgenie**, etc.

### **inhibit_rules**

Stops sending low severity alerts when high severity exists.

---

# ğŸ§© **Slack Receiver Example**

```yaml
receivers:
  - name: "slack-alerts"
    slack_configs:
      - channel: "#alerts"
        send_resolved: true
        title: "ğŸ”¥ Alert: {{ .CommonLabels.alertname }}"
        api_url: "<SLACK_WEBHOOK_URL>"
```

---

# ğŸ”” **Multiple Route Example**

```yaml
route:
  group_by: ["alertname"]
  receiver: "slack-alerts"

  routes:
    - match:
        severity: "critical"
      receiver: "pagerduty"
    - match:
        team: "devops"
      receiver: "email-devops"
```

---

# ğŸ” **Kubernetes Secret Example for Alertmanager**

To apply in kube-prometheus-stack:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-main
  namespace: monitoring
labels:
  alertmanager: "main"
  self-monitor: "true"
data:
  alertmanager.yaml: |
    <BASE64 ENCODED CONTENT>
```

Encode file:

```
cat alertmanager.yml | base64 -w0
```

---

# ğŸš€ If you want, I can prepare:

âœ” **Alertmanager for Slack, Email & Webhook combined**
âœ” **Alertmanager for Teams**
âœ” **Alertmanager with templates**
âœ” **Complete alerting stack for EKS (Prometheus + Alertmanager + Rules)**

Tell me what type you need!
